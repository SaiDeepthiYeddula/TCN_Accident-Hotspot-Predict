{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Binary Classification TCN"
      ],
      "metadata": {
        "id": "kzn7MCoowlkl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twBpzsORwbDy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import geoopt\n",
        "import torch\n",
        "from tcn import TCN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load the data from a local file\n",
        "dataset = pd.read_csv(\"sorted_preprocessed_acc_data_with_hotspots.csv\")\n",
        "X = dataset.iloc[:,0:37]\n",
        "#print('X_previous.shape', X.shape)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "dataset_X = scaler.fit_transform(X)\n",
        "\n",
        "y = dataset.iloc[:,37:38]\n",
        "\n",
        "print('X.shape', X.shape)\n",
        "print('y.shape', y.shape)\n",
        "\n",
        "# Split data into train and test sets\n",
        "'''train_size = int(0.8 * len(dataset))\n",
        "X_train = dataset_X[:train_size]\n",
        "y_train = y[:train_size]\n",
        "X_test = dataset_X[train_size:]\n",
        "y_test = y[train_size:]'''\n",
        "\n",
        "\n",
        "train_ratio = 0.80\n",
        "val_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "train_split = int(len(dataset) * train_ratio)\n",
        "val_split = int(len(dataset) * (train_ratio + val_ratio))\n",
        "\n",
        "X_train = dataset_X[:train_split]\n",
        "y_train = y[:train_split]\n",
        "X_val = dataset_X[train_split:val_split]\n",
        "y_val = y[train_split:val_split]\n",
        "X_test = dataset_X[val_split:]\n",
        "y_test = y[val_split:]\n",
        "\n",
        "'''X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)'''\n",
        "\n",
        "\n",
        "# Define a TCN model for binary classification\n",
        "model = Sequential()\n",
        "model.add(TCN(input_shape=(X_train.shape[1], 1), nb_filters=32, kernel_size=3, activation='relu', dropout_rate=0.3))\n",
        "#model.add(Dense(units=1, activation='linear'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))  # Use sigmoid activation for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Use binary_crossentropy loss for binary classification\n",
        "'''X_train = X_train.numpy()\n",
        "X_val = X_val.numpy()\n",
        "\n",
        "X_test = X_test.numpy()'''\n",
        "\n",
        "# Train the model\n",
        "#model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), shuffle=False)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_classes)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_classes)\n",
        "\n",
        "# Compute confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_classes).ravel()\n",
        "tpr_score = tp / (tp + fn)\n",
        "fpr_score = fp / (fp + tn)\n",
        "report = classification_report(y_test, y_pred_classes, target_names=['Class 0', 'Class 1'])\n",
        "\n",
        "print(report)\n",
        "print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
        "print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Training Loss:\", history.history['loss'][-1])\n",
        "print(\"Validation Loss:\", history.history['val_loss'][-1])\n",
        "print(\"Test Loss:\", model.evaluate(X_test, y_test, verbose=0))\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"True Positive Rate:\", tpr_score)\n",
        "print(\"False Positive Rate:\", fpr_score)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('/content/drive/MyDrive/conf_proj/figures/tcn_roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi classification TCN"
      ],
      "metadata": {
        "id": "iQWz62_fwqor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import torch\n",
        "from tcn import TCN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load the data from a local file\n",
        "dataset = pd.read_csv(\"sorted_preprocessed_acc_data_with_3_Class_hotspots.csv\")\n",
        "X = dataset.iloc[:,0:37]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "dataset_X = scaler.fit_transform(X)\n",
        "\n",
        "y = dataset.iloc[:,37:38]\n",
        "\n",
        "# Convert the targets to categorical\n",
        "y = to_categorical(y)\n",
        "\n",
        "print('X.shape', X.shape)\n",
        "print('y.shape', y.shape)\n",
        "\n",
        "\n",
        "train_ratio = 0.80\n",
        "val_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "train_split = int(len(dataset) * train_ratio)\n",
        "val_split = int(len(dataset) * (train_ratio + val_ratio))\n",
        "\n",
        "X_train = dataset_X[:train_split]\n",
        "y_train = y[:train_split]\n",
        "X_val = dataset_X[train_split:val_split]\n",
        "y_val = y[train_split:val_split]\n",
        "X_test = dataset_X[val_split:]\n",
        "y_test = y[val_split:]\n",
        "\n",
        "\n",
        "# Define a hyperbolic neural network model for binary classification\n",
        "model = Sequential()\n",
        "model.add(TCN(input_shape=(X_train.shape[1], 1), nb_filters=64, kernel_size=3, activation='relu', dropout_rate=0.1))\n",
        "model.add(Dense(units=3, activation='softmax'))  # Use softmax activation for multi-class classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use categorical_crossentropy loss for multi-class classification\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), shuffle=False)\n",
        "# Convert history to dataframe and save\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_csv_file = 'history_multi_tcn.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Convert y_test back to class labels\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "# Evaluate the model using classification report\n",
        "\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_mat = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "# Calculate the test loss\n",
        "test_loss, _ = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
        "print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
        "print(\"Confusion Matrix:\\n\", conf_mat)\n",
        "# If you want to plot a ROC curve for multi-class classification, it'll be a bit more involved as you'll need to do it for each class separately\n",
        "# Evaluate the model using classification report\n",
        "report = classification_report(y_test_classes, y_pred_classes, output_dict=True)\n",
        "print(report)\n",
        "# Get precision, recall, and F1-score\n",
        "precision = report['weighted avg']['precision']\n",
        "recall = report['weighted avg']['recall']\n",
        "f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "\n",
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family'] = 'serif' # specify the default font family to be \"serif\"\n",
        "#plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif'] # specify the default serif font to be \"Times New Roman\"\n",
        "\n",
        "# Define a function to plot the training and validation loss\n",
        "def plot_loss(history):\n",
        "    epochs = range(1, len(history.history['loss']) + 1)  # Shift epoch count up by 1\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.plot(epochs, history.history['loss'], label='Training Loss')\n",
        "    plt.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs', fontsize=18)\n",
        "    plt.ylabel('Loss', fontsize=18)\n",
        "    plt.xticks(fontsize=16) # Increase xticks font size\n",
        "    plt.yticks(fontsize=16)\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.savefig('/content/drive/MyDrive/conf_proj/figures/train_val_loss_multi_tcn.png', dpi=300)  # save the figure with a resolution of 300 dpi\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with your history object\n",
        "plot_loss(history)\n"
      ],
      "metadata": {
        "id": "Zye3MD_pwsaI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}